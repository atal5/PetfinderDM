{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pet Adoption Prediction:\n",
    "Animal adoption rates are strongly correlated to the metadata associated with their online profiles, such as descriptive text and photo characteristics. We are trying to predict the Pet Adoption speed based on their listing on the website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install webcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import webcolors\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Defining functions to get color name out of rgb values returned for images(using Google Vision API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if webcolors api doesnt return any color - get the closest color\n",
    "def closest_colour(requested_colour):\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.css3_hex_to_names.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - requested_colour[0]) ** 2\n",
    "        gd = (g_c - requested_colour[1]) ** 2\n",
    "        bd = (b_c - requested_colour[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "# using webcolors api to get color name out of rgb values\n",
    "def get_colour_name(requested_colour):\n",
    "    if(len(requested_colour)) < 3:\n",
    "        return \"\"\n",
    "    try:\n",
    "        closest_name = actual_name = webcolors.rgb_to_name(requested_colour)\n",
    "    except ValueError:\n",
    "        closest_name = closest_colour(requested_colour)\n",
    "        actual_name = None\n",
    "    return closest_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Reading the LabelAnnotations and FaceAnnotations from Image Data (using JSON returned from Google Vision API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# likelihood scores dictionary\n",
    "likelihood_scores = {'UNKNOWN': '0', 'VERY_UNLIKELY': 0, 'UNLIKELY': 1, 'POSSIBLE': 2, 'LIKELY': 3, 'VERY_LIKELY': 4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading all file names from a directory\n",
    "def read_json(path):\n",
    "    json_files = [pos_json for pos_json in os.listdir(path)]\n",
    "    print(\"Total Number of JSON Files: \", len(json_files))\n",
    "    return json_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Finding out the most common Labels in Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing all JSONs and finding out the most frequent labels in the images.\n",
    "def read_most_common_labels(json_files, cutoff, path_to_json):\n",
    "    all_labels = []\n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(path_to_json, js)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "            labelAnnotations = json_text.get('labelAnnotations', 'N/A')\n",
    "            if labelAnnotations != 'N/A':\n",
    "                for label in labelAnnotations:\n",
    "                    all_labels.append(label['description'])\n",
    "\n",
    "    unique_labels = set(all_labels)\n",
    "\n",
    "    important_words = {}\n",
    "    for l in unique_labels:\n",
    "        count = all_labels.count(l)\n",
    "        word = [l]\n",
    "        if count in important_words:\n",
    "            important_words[count].append(l)\n",
    "        else:\n",
    "            important_words[count] = word\n",
    "\n",
    "    # sorted_d = sorted(important_words.items(), key=operator.itemgetter(0), reverse=True)\n",
    "\n",
    "    filtered_words = {k: v for k, v in important_words.items() if k > cutoff}\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of JSON Files:  58311\n"
     ]
    }
   ],
   "source": [
    "path_to_json = 'image/train_metadata/'\n",
    "files = read_json(path_to_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{26729: ['whiskers'],\n",
       " 27037: ['small to medium sized cats'],\n",
       " 20109: ['domestic short haired cat'],\n",
       " 29716: ['dog'],\n",
       " 10215: ['european shorthair'],\n",
       " 26892: ['cat like mammal'],\n",
       " 13295: ['puppy'],\n",
       " 30836: ['carnivoran'],\n",
       " 13057: ['fauna'],\n",
       " 8049: ['aegean cat'],\n",
       " 30544: ['dog breed group'],\n",
       " 27213: ['cat'],\n",
       " 28375: ['snout'],\n",
       " 10308: ['street dog'],\n",
       " 30470: ['dog breed'],\n",
       " 30799: ['dog like mammal'],\n",
       " 8778: ['sporting group'],\n",
       " 20762: ['kitten']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cutoff is set to 8000 words\n",
    "filtered_words = read_most_common_labels(files, 8000, path_to_json)\n",
    "filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whiskers', 'small to medium sized cats', 'domestic short haired cat', 'dog', 'european shorthair', 'cat like mammal', 'puppy', 'carnivoran', 'fauna', 'aegean cat', 'dog breed group', 'cat', 'snout', 'street dog', 'dog breed', 'dog like mammal', 'sporting group', 'kitten']\n"
     ]
    }
   ],
   "source": [
    "label_columns = [v for k, [v] in filtered_words.items()]\n",
    "print(label_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Constructing a DataFrame reading all JSON Files containing Image Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_df_from_json(json_files, df, path_to_json):\n",
    "    for index, js in enumerate(json_files):\n",
    "        with open(os.path.join(path_to_json, js)) as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "            #The json file name is in the format petid-photonum\n",
    "            full_id = js.partition('.json')[0].partition('-')\n",
    "            pet_id = full_id[0]\n",
    "            photo_num = full_id[2]\n",
    "            # Face Annotations and Likelihood Scores\n",
    "            faceAnnotations = json_text.get('faceAnnotations', 'N/A')\n",
    "            detectionConfidence = 0\n",
    "            joyLikelihood = 0\n",
    "            sorrowLikelihood = 0\n",
    "            angerLikelihood = 0\n",
    "            surpriseLikelihood = 0\n",
    "            underExposedLikelihood = 0\n",
    "            blurredLikelihood = 0\n",
    "            headwearLikelihood = 0\n",
    "\n",
    "            if faceAnnotations != 'N/A':\n",
    "                detectionConfidence = faceAnnotations[0]['detectionConfidence']\n",
    "                joyLikelihood = likelihood_scores[faceAnnotations[0]['joyLikelihood']]\n",
    "                sorrowLikelihood = likelihood_scores[faceAnnotations[0]['sorrowLikelihood']]\n",
    "                angerLikelihood = likelihood_scores[faceAnnotations[0]['angerLikelihood']]\n",
    "                surpriseLikelihood = likelihood_scores[faceAnnotations[0]['surpriseLikelihood']]\n",
    "                underExposedLikelihood = likelihood_scores[faceAnnotations[0]['underExposedLikelihood']]\n",
    "                blurredLikelihood = likelihood_scores[faceAnnotations[0]['blurredLikelihood']]\n",
    "                headwearLikelihood = likelihood_scores[faceAnnotations[0]['headwearLikelihood']]\n",
    "            #Detection Score of Popular Labels\n",
    "            labelcount = 0\n",
    "            labels = ''\n",
    "            dog_like_mammal = 0\n",
    "            kitten = 0\n",
    "            puppy = 0\n",
    "            cat_like_mammal = 0\n",
    "            european_shorthair = 0\n",
    "            fauna = 0\n",
    "            carnivoran = 0\n",
    "            cat = 0\n",
    "            snout = 0\n",
    "            domestic_short_haired_cat = 0\n",
    "            dog = 0\n",
    "            dog_breed_group = 0\n",
    "            small_to_medium_sized_cats = 0\n",
    "            aegean_cat = 0\n",
    "            sporting_group = 0\n",
    "            street_dog = 0\n",
    "            whiskers = 0\n",
    "            dog_breed = 0\n",
    "\n",
    "            labelAnnotations = json_text.get('labelAnnotations', 'N/A')\n",
    "            if labelAnnotations != 'N/A':\n",
    "                for label in labelAnnotations:\n",
    "                    labelcount += 1\n",
    "                    labels = labels + label['description']\n",
    "                    if label['description'] == 'dog like mammal':\n",
    "                        dog_like_mammal = label['score']\n",
    "                    elif label['description'] == 'kitten':\n",
    "                        kitten = label['score']\n",
    "                    elif label['description'] == 'puppy':\n",
    "                        puppy = label['score']\n",
    "                    elif label['description'] == 'cat like mammal':\n",
    "                        cat_like_mammal = label['score']\n",
    "                    elif label['description'] == 'european shorthair':\n",
    "                        european_shorthair = label['score']\n",
    "                    elif label['description'] == 'fauna':\n",
    "                        fauna = label['score']\n",
    "                    elif label['description'] == 'carnivoran':\n",
    "                        carnivoran = label['score']\n",
    "                    elif label['description'] == 'cat':\n",
    "                        cat = label['score']\n",
    "                    elif label['description'] == 'snout':\n",
    "                        snout = label['score']\n",
    "                    elif label['description'] == 'domestic short haired cat':\n",
    "                        domestic_short_haired_cat = label['score']\n",
    "                    elif label['description'] == 'dog':\n",
    "                        dog = label['score']\n",
    "                    elif label['description'] == 'dog breed group':\n",
    "                        dog_breed_group = label['score']\n",
    "                    elif label['description'] == 'small to medium sized cats':\n",
    "                        small_to_medium_sized_cats = label['score']\n",
    "                    elif label['description'] == 'aegean cat':\n",
    "                        aegean_cat = label['score']\n",
    "                    elif label['description'] == 'sporting group':\n",
    "                        sporting_group = label['score']\n",
    "                    elif label['description'] == 'street dog':\n",
    "                        street_dog = label['score']\n",
    "                    elif label['description'] == 'whiskers':\n",
    "                        whiskers = label['score']\n",
    "                    elif label['description'] == 'dog breed':\n",
    "                        dog_breed = label['score']\n",
    "\n",
    "            cropHintsConfidence = 0\n",
    "            cropHintsAnnotation = json_text.get('cropHintsAnnotation', 'N/A')\n",
    "            if cropHintsAnnotation != 'N/A':\n",
    "                cropHintsConfidence = cropHintsAnnotation['cropHints'][0]['confidence']\n",
    "\n",
    "            color1 = \"\"\n",
    "            color2 = \"\"\n",
    "            color3 = \"\"\n",
    "            colors_in_image = 0\n",
    "\n",
    "            imagePropertiesAnnotation = json_text.get('imagePropertiesAnnotation', 'N/A')\n",
    "            if imagePropertiesAnnotation != 'N/A':\n",
    "                colorlist = imagePropertiesAnnotation['dominantColors']['colors']\n",
    "                colors_in_image = len(colorlist)\n",
    "                colorlist = sorted(colorlist, key=lambda k: k['score'], reverse=True)[:3]\n",
    "                # Checking if colors in the csv data matches colors in Images\n",
    "                if colors_in_image > 0:\n",
    "                    color1 = get_colour_name(tuple(colorlist[0]['color'][e] for e in colorlist[0]['color']))\n",
    "                if colors_in_image > 1:\n",
    "                    color2 = get_colour_name(tuple(colorlist[1]['color'][e] for e in colorlist[1]['color']))\n",
    "                if colors_in_image > 2:\n",
    "                    color3 = get_colour_name(tuple(colorlist[2]['color'][e] for e in colorlist[2]['color']))\n",
    "\n",
    "            df.loc[index] = [pet_id, photo_num, detectionConfidence, joyLikelihood,\n",
    "                             sorrowLikelihood,\n",
    "                             angerLikelihood, surpriseLikelihood,\n",
    "                             underExposedLikelihood,\n",
    "                             blurredLikelihood, headwearLikelihood,\n",
    "                             labels, labelcount, cropHintsConfidence, color1, color2,\n",
    "                             color3, colors_in_image,\n",
    "                             street_dog,\n",
    "                             dog_like_mammal, aegean_cat, carnivoran,\n",
    "                             small_to_medium_sized_cats,\n",
    "                             cat_like_mammal, dog_breed, snout,\n",
    "                             whiskers, domestic_short_haired_cat,\n",
    "                             puppy, dog_breed_group,\n",
    "                             fauna, kitten, european_shorthair, dog, sporting_group, cat]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Images\n",
    "df_columns = ['petid', 'photo_num', 'detectionConfidence', 'joyLikelihood',\n",
    "              'sorrowLikelihood', 'angerLikelihood', 'surpriseLikelihood',\n",
    "              'underExposedLikelihood', 'blurredLikelihood', 'headwearLikelihood',\n",
    "              'labels', 'labelcount', 'cropHintsConfidence', 'color1', 'color2', 'color3', 'colors_in_image',\n",
    "              'street dog',\n",
    "              'dog like mammal', 'aegean cat',\n",
    "              'carnivoran',\n",
    "              'small to medium sized cats', 'cat like mammal', 'dog breed', 'snout',\n",
    "              'whiskers', 'domestic short haired cat', 'puppy', 'dog breed group',\n",
    "              'fauna', 'kitten', 'european shorthair', 'dog', 'sporting group', 'cat']\n",
    "\n",
    "pet_image_data = pd.DataFrame(columns=df_columns)\n",
    "pet_image_data = construct_df_from_json(files, pet_image_data, path_to_json)\n",
    "pet_image_data.to_pickle(\"image/pet_image_data_trainv1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of JSON Files:  15040\n"
     ]
    }
   ],
   "source": [
    "# Test Images\n",
    "path_to_json = 'image/test_metadata/'\n",
    "test_files = read_json(path_to_json)\n",
    "df_columns = ['petid', 'photo_num', 'detectionConfidence', 'joyLikelihood',\n",
    "              'sorrowLikelihood', 'angerLikelihood', 'surpriseLikelihood',\n",
    "              'underExposedLikelihood', 'blurredLikelihood', 'headwearLikelihood',\n",
    "              'labels', 'labelcount', 'cropHintsConfidence', 'color1', 'color2', 'color3', 'colors_in_image',\n",
    "              'street dog',\n",
    "              'dog like mammal', 'aegean cat',\n",
    "              'carnivoran',\n",
    "              'small to medium sized cats', 'cat like mammal', 'dog breed', 'snout',\n",
    "              'whiskers', 'domestic short haired cat', 'puppy', 'dog breed group',\n",
    "              'fauna', 'kitten', 'european shorthair', 'dog', 'sporting group', 'cat']\n",
    "pet_image_data_test = pd.DataFrame(columns=df_columns)\n",
    "pet_image_data_test = construct_df_from_json(test_files, pet_image_data_test, path_to_json)\n",
    "pet_image_data_test.to_pickle(\"image/pet_image_data_testv1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cleaning the Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image(df):\n",
    "    df['photo_num'] = df['photo_num'].astype('int')\n",
    "    df['detectionConfidence'] = df['detectionConfidence'].astype('float')\n",
    "    df['cropHintsConfidence'] = df['cropHintsConfidence'].astype('float')\n",
    "    df['joyLikelihood'] = df['joyLikelihood'].astype('int')\n",
    "    df['colors_in_image'] = df['colors_in_image'].astype('int')\n",
    "    df['sorrowLikelihood'] = df['sorrowLikelihood'].astype('int')\n",
    "    df['angerLikelihood'] = df['angerLikelihood'].astype('int')\n",
    "    df['surpriseLikelihood'] = df['surpriseLikelihood'].astype('int')\n",
    "    df['underExposedLikelihood'] = df['underExposedLikelihood'].astype('int')\n",
    "    df['blurredLikelihood'] = df['blurredLikelihood'].astype('int')\n",
    "    df['headwearLikelihood'] = df['headwearLikelihood'].astype('int')\n",
    "    df['labelcount'] = df['labelcount'].astype('int')\n",
    "    df['street dog'] = df['street dog'].astype('float')\n",
    "    df['dog like mammal'] = df['dog like mammal'].astype('float')\n",
    "    df['aegean cat'] = df['aegean cat'].astype('float')\n",
    "    df['carnivoran'] = df['carnivoran'].astype('float')\n",
    "    df['small to medium sized cats'] = df['small to medium sized cats'].astype('float')\n",
    "    df['cat like mammal'] = df['cat like mammal'].astype('float')\n",
    "    df['dog breed'] = df['dog breed'].astype('float')\n",
    "    df['snout'] = df['snout'].astype('float')\n",
    "    df['whiskers'] = df['whiskers'].astype('float')\n",
    "    df['domestic short haired cat'] = df['domestic short haired cat'].astype('float')\n",
    "    df['puppy'] = df['puppy'].astype('float')\n",
    "    df['dog breed group'] = df['dog breed group'].astype('float')\n",
    "    df['fauna'] = df['fauna'].astype('float')\n",
    "    df['kitten'] = df['kitten'].astype('float')\n",
    "    df['european shorthair'] = df['european shorthair'].astype('float')\n",
    "    df['dog'] = df['dog'].astype('float')\n",
    "    df['sporting group'] = df['sporting group'].astype('float')\n",
    "    df['cat'] = df['cat'].astype('float')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the first version of Image data in pickel files. \n",
    "train_images = pd.read_pickle(\"image/pet_image_data_trainv1.pkl\")\n",
    "test_images = pd.read_pickle(\"image/pet_image_data_testv1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = clean_image(train_images)\n",
    "test_images = clean_image(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 - Aggregating the Image Data.\n",
    "Pets have more than 1 images. It is found that the first image is very useful to predict the Adoption Speed. Here we are aggregating the features of 1st Image with 80% weightage and the rest of the images have 20% weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_photos(df):\n",
    "    columns = ['petid', 'photo_num', 'labels', 'color1', 'color2', 'color3']\n",
    "    categoricals = df[columns]\n",
    "    categoricals = categoricals[categoricals['photo_num'] == 1]\n",
    "    categoricals.drop(columns=['photo_num'], inplace=True)\n",
    "    df = df.drop(columns=['labels', 'color1', 'color2', 'color3'])\n",
    "    first_photo = df[df['photo_num'] == 1]\n",
    "    rest_photo = df[df['photo_num'] != 1]\n",
    "    first_photo = first_photo.groupby('petid').sum() * 0.8\n",
    "    rest_photo = rest_photo.groupby('petid').sum() * 0.2\n",
    "    all_photos = pd.concat([first_photo, rest_photo])\n",
    "    all_photos = all_photos.groupby('petid').sum()\n",
    "    all_photos.reset_index(inplace=True)\n",
    "    all_photos = pd.merge(all_photos, categoricals, on='petid')\n",
    "\n",
    "    all_photos.drop(columns=['photo_num'], inplace=True)\n",
    "\n",
    "    return all_photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = aggregate_photos(train_images)\n",
    "test_images = aggregate_photos(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.to_pickle(\"image/pet_image_data_trainv2.pkl\")\n",
    "test_images.to_pickle(\"image/pet_image_data_testv2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Working on the Structured CSV Features - train.csv and test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"csvfeatures/train.csv\")\n",
    "test_df = pd.read_csv(\"csvfeatures/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Cleaning up and creating some extra Features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup(df):\n",
    "    df['Name'].fillna('No Name', inplace=True)\n",
    "    df['NumColors'] = df.loc[:, 'Color1':'Color3'].apply(\n",
    "        lambda row: bool(row.Color1) + bool(row.Color2) + bool(row.Color3), axis=1)\n",
    "    df['IsMixedBreed'] = df.loc[:, 'Breed1':'Breed2'].apply(\n",
    "        lambda row: bool(row.Breed1) * bool(row.Breed2), axis=1)\n",
    "    name_frequency_df = pd.DataFrame(df['Name'].value_counts())\n",
    "    df['NameFrequency'] = name_frequency_df.loc[df['Name'], 'Name'].values\n",
    "    df['Description'].fillna('', inplace=True)\n",
    "    df['WordCount'] = df['Description'].str.split().apply(lambda x: len(x))\n",
    "    df = df.drop('Description', axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy_df = cleanup(train_df)\n",
    "test_copy_df = cleanup(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy_df.to_pickle(\"csvfeatures/trainv1.pkl\")\n",
    "test_copy_df.to_pickle(\"csvfeatures/testv1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: We have included a separate notebook with our submission that includes the EDA and Feature Engineering steps and explains how we created the test_cleaned_Features_v2.pk and train_cleaned_Features_v2.pk files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_pickle('cleanedData/test_cleaned_Features_v2.pk')\n",
    "train = pd.read_pickle('cleanedData/train_cleaned_Features_v2.pk')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Some More Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out popular breeds in the data\n",
    "popularBreeds = train.loc[train['AdoptionSpeed'] == 0, ['Breed1', 'Breed2']]\n",
    "popularBreed1 = popularBreeds['Breed1'].unique()\n",
    "popularBreed2 = popularBreeds['Breed2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda(data):\n",
    "    # Name\n",
    "    data['hasName'] = data['Name'] != 'No Name'\n",
    "    data['hasName'] = data['hasName'].astype('int')\n",
    "\n",
    "    # Age\n",
    "    data['isYoung'] = (data['Age'] < 2).astype('int')\n",
    "    data['isOld'] = (data['Age'] > 12).astype('int')\n",
    "\n",
    "    # Breed\n",
    "\n",
    "    data['ispopularBreed1'] = data.apply(lambda x: x['Breed1'] in popularBreed1, axis=1).astype('int')\n",
    "    data['ispopularBreed2'] = data.apply(lambda x: x['Breed2'] in popularBreed2, axis=1).astype('int')\n",
    "\n",
    "    # mapping color with colorlabels\n",
    "    colorlabels = pd.read_csv('csvfeatures/color_labels.csv')\n",
    "    data['color1Name'] = data['Color1'].map(colorlabels.set_index('ColorID')['ColorName'])\n",
    "    data['color2Name'] = data['Color2'].map(colorlabels.set_index('ColorID')['ColorName'])\n",
    "    data['color3Name'] = data['Color3'].map(colorlabels.set_index('ColorID')['ColorName'])\n",
    "    data[['color1Name', 'color2Name', 'color3Name']] = data[['color1Name', 'color2Name', 'color3Name']].fillna(\n",
    "        'No Color')\n",
    "\n",
    "    data.drop(columns=['Color1', 'Color2', 'Color3'], inplace=True)\n",
    "\n",
    "    # Merge Image color data and see if color in image matches color in csv\n",
    "    # TO DO\n",
    "\n",
    "    # De-wormed\n",
    "    data['Dewormed'] = data['Dewormed'].astype('category')\n",
    "\n",
    "    # Fee\n",
    "    data['isNotFree'] = (data['Fee'] != 0).astype('int')\n",
    "\n",
    "    # FurLength\n",
    "    data['FurLength'] = data['FurLength'].astype('category')\n",
    "\n",
    "    # Gender\n",
    "    data['Gender'] = data['Gender'].astype('category')\n",
    "\n",
    "    # Health\n",
    "    data['Health'] = data['Health'].astype('category')\n",
    "\n",
    "    # Quantity\n",
    "    data['isSingle'] = (data['Quantity'] == 1).astype('int')\n",
    "\n",
    "    # State\n",
    "    data['State'] = data['State'].astype('category')\n",
    "\n",
    "    # Sterilized\n",
    "    data['Sterilized'] = data['Sterilized'].astype('category')\n",
    "\n",
    "    # Type\n",
    "    data['Type'] = data['Type'].astype('category')\n",
    "\n",
    "    # Vaccinated\n",
    "    data['Vaccinated'] = data['Vaccinated'].astype('category')\n",
    "\n",
    "    # Videos\n",
    "    data['hasVideo'] = (data['VideoAmt'] > 1).astype('int')\n",
    "\n",
    "    data['hasLotOfVideos'] = (data['VideoAmt'] > 5).astype('int')\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = eda(train)\n",
    "test = eda(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('cleanedData/csv_features_trainv3.pkl')\n",
    "test.to_pickle('cleanedData/csv_features_testv3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merging the Image and CSV Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_pickle('cleanedData/csv_features_trainv3.pkl')\n",
    "test_features = pd.read_pickle('cleanedData/csv_features_testv3.pkl')\n",
    "\n",
    "train_images = pd.read_pickle('image/pet_image_data_trainv2.pkl')\n",
    "test_images = pd.read_pickle('image/pet_image_data_testv2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeandCreateFeatures(features, images):\n",
    "    completeData = pd.merge(features, images, left_on='PetID', right_on='petid', how='left')\n",
    "    completeData.drop(columns=['petid'], inplace=True)\n",
    "\n",
    "    breed_labels = pd.read_csv('csvfeatures/breed_labels.csv')\n",
    "\n",
    "    completeData['breed1Name'] = completeData['Breed1'].map(breed_labels.set_index('BreedID')['BreedName'])\n",
    "    completeData['breed2Name'] = completeData['Breed2'].map(breed_labels.set_index('BreedID')['BreedName'])\n",
    "    completeData['breed2Name'].fillna(\"not_recognized\", inplace=True)\n",
    "\n",
    "    completeData['labels'].fillna(\" \", inplace=True)\n",
    "    completeData['breed1Name'].fillna(\"not_recognized\", inplace=True)\n",
    "\n",
    "    completeData['breed1Name'] = completeData['breed1Name'].str.lower()\n",
    "    completeData['breed2Name'] = completeData['breed2Name'].str.lower()\n",
    "    completeData['labels'] = completeData['labels'].str.lower()\n",
    "\n",
    "    completeData['isBreed1Matching'] = completeData[['breed1Name', 'labels']].apply(\n",
    "        lambda x: x['breed1Name'] in x['labels'], axis=1).astype('int')\n",
    "    completeData['isBreed2Matching'] = completeData[['breed2Name', 'labels']].apply(\n",
    "        lambda x: x['breed2Name'] in x['labels'], axis=1).astype('int')\n",
    "\n",
    "    # colors from csv features\n",
    "    completeData['color1Name'] = completeData['color1Name'].str.lower()\n",
    "    completeData['color2Name'] = completeData['color2Name'].str.lower()\n",
    "    completeData['color3Name'] = completeData['color3Name'].str.lower()\n",
    "\n",
    "    # colors from images\n",
    "    completeData['color1'] = completeData['color1'].str.lower()\n",
    "    completeData['color2'] = completeData['color2'].str.lower()\n",
    "    completeData['color3'] = completeData['color3'].str.lower()\n",
    "\n",
    "    completeData['iscolor1Matching'] = (completeData['color1'] == completeData['color1Name']).astype('int')\n",
    "    completeData['iscolor2Matching'] = (completeData['color2'] == completeData['color2Name']).astype('int')\n",
    "    completeData['iscolor3Matching'] = (completeData['color3'] == completeData['color3Name']).astype('int')\n",
    "\n",
    "    # Null Values\n",
    "    completeData.loc[:, 'detectionConfidence': 'cat'] = completeData.loc[:, 'detectionConfidence': 'cat'].fillna(0)\n",
    "    completeData.loc[:, 'color1': 'color3'] = completeData.loc[:, 'color1': 'color3'].fillna(\"\")\n",
    "\n",
    "    return completeData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_train = mergeandCreateFeatures(train_features, train_images)\n",
    "complete_test = mergeandCreateFeatures(test_features, test_images)\n",
    "\n",
    "complete_train.to_pickle('cleanedData/complete_train.pkl')\n",
    "complete_test.to_pickle('cleanedData/complete_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Text Sentiment Analysis using CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach is to run a separate model on the 'Description' column that tries to prediction the Adotpion Speed between 0 to 4. Then use the probabilities returned from the model, aggregate it with the rest of the data and run further models. We are using a Model Stacking Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Using StratifiedKFold, generate prediction probabilities for Adoption Speed based on the Description 'Vector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stacking(model, train, y, test, n_fold):\n",
    "    folds = StratifiedKFold(n_splits=n_fold, random_state=1)\n",
    "    test_pred = pd.DataFrame()\n",
    "    test_pred_proba = pd.DataFrame()\n",
    "    train_pred = pd.DataFrame()\n",
    "    train_pred_prob = pd.DataFrame()\n",
    "    \n",
    "    for train_indices, val_indices in folds.split(train, y.values):\n",
    "        x_train, x_val = train.iloc[train_indices], train.iloc[val_indices]\n",
    "        y_train, y_val = y.iloc[train_indices], y.iloc[val_indices]\n",
    "        model.fit(X=x_train, y=y_train)\n",
    "        train_pred = pd.concat([train_pred, pd.Series(model.predict(x_val))], axis=0)\n",
    "        print(\"Accuracy Score:\", round(accuracy_score(y_val, pd.Series(model.predict(x_val))) * 100, 2))\n",
    "        train_pred_prob = pd.concat([train_pred_prob, pd.DataFrame(model.predict_proba(x_val))], axis=0)\n",
    "        test_pred = pd.concat([test_pred, pd.Series(model.predict(test))], axis=1)\n",
    "        test_pred_proba = pd.concat([test_pred_proba, pd.DataFrame(model.predict_proba(test))], axis=1)\n",
    "        \n",
    "    # Combine probabilities by multiplying.\n",
    "    test_pred_proba['x0'] = test_pred_proba.iloc[:, 0] * test_pred_proba.iloc[:, 5]\n",
    "    test_pred_proba['x1'] = test_pred_proba.iloc[:, 1] * test_pred_proba.iloc[:, 6]\n",
    "    test_pred_proba['x2'] = test_pred_proba.iloc[:, 2] * test_pred_proba.iloc[:, 7]\n",
    "    test_pred_proba['x3'] = test_pred_proba.iloc[:, 3] * test_pred_proba.iloc[:, 8]\n",
    "    test_pred_proba['x4'] = test_pred_proba.iloc[:, 4] * test_pred_proba.iloc[:, 9]\n",
    "\n",
    "    test_pred_proba = test_pred_proba[['x0', 'x1', 'x2', 'x3', 'x4']]\n",
    "\n",
    "    return test_pred, train_pred, train_pred_prob, test_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read description from the train and test data\n",
    "train = pd.read_csv('csvfeatures/train.csv')\n",
    "train['Description'].fillna('', inplace=True)\n",
    "train['length'] = train['Description'].apply(len)\n",
    "test = pd.read_csv('csvfeatures/test.csv')\n",
    "test['Description'].fillna('', inplace=True)\n",
    "test['length'] = test['Description'].apply(len)\n",
    "\n",
    "data_classes = train\n",
    "\n",
    "x = data_classes['Description']\n",
    "y = data_classes['AdoptionSpeed']\n",
    "x_holdout = test['Description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Use a CountVectorizer to convert the description into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "\n",
    "\n",
    "vocab = CountVectorizer(analyzer=text_process).fit(x)\n",
    "r0 = x[0]\n",
    "vocab0 = vocab.transform([r0])\n",
    "\n",
    "x = vocab.transform(x)\n",
    "x = pd.DataFrame(x.todense(), columns=vocab.get_feature_names())\n",
    "\n",
    "x_holdout = vocab.transform(x_holdout)\n",
    "x_holdout = pd.DataFrame(x_holdout.todense(), columns=vocab.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Run a Random Forest on the vectorized description using the stacking function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 39.6\n",
      "Accuracy Score: 40.6\n",
      "Accuracy Score: 41.0\n",
      "Accuracy Score: 40.6\n",
      "Accuracy Score: 38.73\n",
      "Accuracy Score: 39.53\n",
      "Accuracy Score: 38.8\n",
      "Accuracy Score: 40.19\n",
      "Accuracy Score: 41.46\n",
      "Accuracy Score: 39.81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfr = RandomForestClassifier(n_estimators=150)\n",
    "\n",
    "test_predicted_sentiment_class, train_predicted_sentiment_class, train_predicted_sentiment, test_predicted_sentiment = Stacking(\n",
    "    model=rmfr, n_fold=10, train=x, test=x_holdout, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4  - Below are really time Taking Algos - will have to settle with Random Forests only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from xgboost import XGBClassifier\n",
    "# xgb = XGBClassifier()\n",
    "# test_predicted_sentiment_class, train_predicted_sentiment_class, train_predicted_sentiment, test_predicted_sentiment = Stacking(\n",
    "#     model=xgb, n_fold=10, train=x, test=x_holdout, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# mlp = MLPClassifier()\n",
    "# test_predicted_sentiment_class, train_predicted_sentiment_class, train_predicted_sentiment, test_predicted_sentiment = Stacking(\n",
    "#     model=mlp, n_fold=10, train=x, test=x_holdout, y=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.5 Save the predictions from Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predicted_sentiment.to_pickle('text/train_predicted_sentiment.pkl')\n",
    "train_predicted_sentiment_class.to_pickle('text/train_predicted_sentiment_class.pkl')\n",
    "test_predicted_sentiment.to_pickle('text/test_predicted_sentiment.pkl')\n",
    "test_predicted_sentiment_class.to_pickle('text/test_predicted_sentiment_class.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Run Stacking Predictions\n",
    "Aggregate the cleaned data with the results of the sentiment analysis and run Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Ordinal Responses\n",
    "Here, we are trying to run five different models:\n",
    "1. 1st model to prediction if the Adoption speed will be 0 or not\n",
    "2. 2nd model to prediction if the Adoption speed will be 1 or not\n",
    "3. 3rd model to prediction if the Adoption speed will be 2 or not\n",
    "4. 4th model to prediction if the Adoption speed will be 3 or not\n",
    "5. 5th model to prediction if the Adoption speed will be 4 or not\n",
    "\n",
    "We then combine the probabilities of all models and try to derive the final results.\n",
    "\n",
    "Also, we multiply the probability of not having 0 adoption speed by 0.8 - since our sample is imbalanced and we need to give some weight to Adoption Speed 0 as well. This approach eventually improves our score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_stacking_predictions(modelObject, modelName, abbv):\n",
    "    pd.set_option('display.max_columns', 100)\n",
    "\n",
    "    test_predictions_prob = pd.read_pickle('text/test_predicted_sentiment.pkl')\n",
    "    test_predictions_prob.columns = ['x0', 'x1', 'x2', 'x3', 'x4']\n",
    "\n",
    "    train_predictions_prob = pd.read_pickle('text/train_predicted_sentiment.pkl')\n",
    "    train_predictions_prob.columns = ['x0', 'x1', 'x2', 'x3', 'x4']\n",
    "\n",
    "    data = pd.read_pickle('cleanedData/complete_train.pkl')\n",
    "    print(data.shape)\n",
    "    train_predictions_prob.reset_index(inplace=True, drop=True)\n",
    "    data = pd.concat([train_predictions_prob , data], axis=1)\n",
    "    print(data.shape)\n",
    "\n",
    "\n",
    "    # some last minute cleaning\n",
    "    categoricals = ['Dewormed', 'FurLength', 'Gender', 'Health', 'State', 'Sterilized', 'Type', 'Vaccinated',\n",
    "                    'color1Name', 'color2Name', 'color3Name']\n",
    "    data = pd.get_dummies(data, columns=categoricals)\n",
    "\n",
    "    X = data.drop(['Name',\n",
    "                   'PetID',\n",
    "                   'AdoptionSpeed',\n",
    "                   'Description',\n",
    "                   'labels',\n",
    "                   'color1',\n",
    "                   'color2',\n",
    "                   'color3',\n",
    "                   'breed1Name',\n",
    "                   'breed2Name',\n",
    "                   'iscolor3Matching',\n",
    "                   'RescuerID'], axis=1)\n",
    "    y = data['AdoptionSpeed']\n",
    "\n",
    "    data_test = pd.read_pickle('cleanedData/complete_test.pkl')\n",
    "    print(data_test.shape)\n",
    "    test_predictions_prob.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    data_test = pd.concat([test_predictions_prob, data_test], axis=1)\n",
    "    print(data_test.shape)\n",
    "\n",
    "    data_test = pd.get_dummies(data_test, columns=categoricals)\n",
    "\n",
    "    X_holdout = data_test.drop(['Name',\n",
    "                                'PetID',\n",
    "                                'AdoptionSpeed',\n",
    "                                'Description',\n",
    "                                'labels',\n",
    "                                'color1',\n",
    "                                'color2',\n",
    "                                'color3',\n",
    "                                'breed1Name',\n",
    "                                'breed2Name',\n",
    "                                'iscolor3Matching',\n",
    "                                'RescuerID'], axis=1)\n",
    "\n",
    "    missing_cols = set(X.columns) - set(X_holdout.columns)\n",
    "    for c in missing_cols:\n",
    "        X_holdout[c] = 0\n",
    "\n",
    "    X_holdout = X_holdout[X.columns]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "    # class 0 vs rest\n",
    "    print(\"Fitting 1st Model - Class 0 vs rest\")\n",
    "    y0 = (y_train == 0).astype('int')\n",
    "    modelObject.fit(x_train, y0)\n",
    "    y_pred0_test = pd.DataFrame(modelObject.predict_proba(x_test)[:, 0] * 0.8)\n",
    "    y_pred0_train = pd.DataFrame(modelObject.predict_proba(x_train)[:, 0] * 0.8)\n",
    "    y_pred0_holdout = pd.DataFrame(modelObject.predict_proba(X_holdout)[:, 0] * 0.8)\n",
    "    y_pred_test = y_pred0_test\n",
    "    y_pred_train = y_pred0_train\n",
    "    y_pred_holdout = y_pred0_holdout\n",
    "\n",
    "    # class 1 vs rest\n",
    "    print(\"Fitting 2nd - Class 1 vs rest\")\n",
    "    y1 = (y_train == 1).astype('int')\n",
    "    modelObject.fit(x_train, y1)\n",
    "    y_pred1_test = pd.DataFrame(modelObject.predict_proba(x_test)[:, 0])\n",
    "    y_pred1_train = pd.DataFrame(modelObject.predict_proba(x_train)[:, 0])\n",
    "    y_pred1_holdout = pd.DataFrame(modelObject.predict_proba(X_holdout)[:, 0])\n",
    "    y_pred_test = pd.concat([y_pred_test, y_pred1_test], axis=1)\n",
    "    y_pred_train = pd.concat([y_pred_train, y_pred1_train], axis=1)\n",
    "    y_pred_holdout = pd.concat([y_pred_holdout, y_pred1_holdout], axis=1)\n",
    "\n",
    "    # class 2 vs rest\n",
    "    print(\"Fitting 3rd - Class 2 vs rest\")\n",
    "    y2 = (y_train == 2).astype('int')\n",
    "    modelObject.fit(x_train, y2)\n",
    "    y_pred2_test = pd.DataFrame(modelObject.predict_proba(x_test)[:, 0])\n",
    "    y_pred2_train = pd.DataFrame(modelObject.predict_proba(x_train)[:, 0])\n",
    "    y_pred2_holdout = pd.DataFrame(modelObject.predict_proba(X_holdout)[:, 0])\n",
    "    y_pred_test = pd.concat([y_pred_test, y_pred2_test], axis=1)\n",
    "    y_pred_train = pd.concat([y_pred_train, y_pred2_train], axis=1)\n",
    "    y_pred_holdout = pd.concat([y_pred_holdout, y_pred2_holdout], axis=1)\n",
    "\n",
    "    # class 3 vs rest\n",
    "    print(\"Fitting 4th - Class 3 vs rest\")\n",
    "    y3 = (y_train == 3).astype('int')\n",
    "    modelObject.fit(x_train, y3)\n",
    "    y_pred3_test = pd.DataFrame(modelObject.predict_proba(x_test)[:, 0])\n",
    "    y_pred3_train = pd.DataFrame(modelObject.predict_proba(x_train)[:, 0])\n",
    "    y_pred3_holdout = pd.DataFrame(modelObject.predict_proba(X_holdout)[:, 0])\n",
    "    y_pred_test = pd.concat([y_pred_test, y_pred3_test], axis=1)\n",
    "    y_pred_train = pd.concat([y_pred_train, y_pred3_train], axis=1)\n",
    "    y_pred_holdout = pd.concat([y_pred_holdout, y_pred3_holdout], axis=1)\n",
    "\n",
    "    # class 4 vs rest\n",
    "    print(\"Fitting 5th - class 4 vs rest\")\n",
    "    y4 = (y_train == 4).astype('int')\n",
    "    modelObject.fit(x_train, y4)\n",
    "    y_pred4_test = pd.DataFrame(modelObject.predict_proba(x_test)[:, 0])\n",
    "    y_pred4_train = pd.DataFrame(modelObject.predict_proba(x_train)[:, 0])\n",
    "    y_pred4_holdout = pd.DataFrame(modelObject.predict_proba(X_holdout)[:, 0])\n",
    "    y_pred_test = pd.concat([y_pred_test, y_pred4_test], axis=1)\n",
    "    y_pred_train = pd.concat([y_pred_train, y_pred4_train], axis=1)\n",
    "    y_pred_holdout = pd.concat([y_pred_holdout, y_pred4_holdout], axis=1)\n",
    "\n",
    "    y_pred_test.columns = ['not0', 'not1', 'not2', 'not3', 'not4']\n",
    "    y_pred_train.columns = ['not0', 'not1', 'not2', 'not3', 'not4']\n",
    "    y_pred_holdout.columns = ['not0', 'not1', 'not2', 'not3', 'not4']\n",
    "\n",
    "    # Combining Probabilities from 5 models\n",
    "    y_pred_test['0'] = y_pred_test['not1'] + y_pred_test['not2'] + y_pred_test['not3'] + y_pred_test['not4']\n",
    "    y_pred_test['1'] = y_pred_test['not0'] + y_pred_test['not2'] + y_pred_test['not3'] + y_pred_test['not4']\n",
    "    y_pred_test['2'] = y_pred_test['not1'] + y_pred_test['not0'] + y_pred_test['not3'] + y_pred_test['not4']\n",
    "    y_pred_test['3'] = y_pred_test['not1'] + y_pred_test['not2'] + y_pred_test['not0'] + y_pred_test['not4']\n",
    "    y_pred_test['4'] = y_pred_test['not1'] + y_pred_test['not2'] + y_pred_test['not3'] + y_pred_test['not0']\n",
    "\n",
    "    y_pred_train['0'] = y_pred_train['not1'] + y_pred_train['not2'] + y_pred_train['not3'] + y_pred_train['not4']\n",
    "    y_pred_train['1'] = y_pred_train['not0'] + y_pred_train['not2'] + y_pred_train['not3'] + y_pred_train['not4']\n",
    "    y_pred_train['2'] = y_pred_train['not1'] + y_pred_train['not0'] + y_pred_train['not3'] + y_pred_train['not4']\n",
    "    y_pred_train['3'] = y_pred_train['not1'] + y_pred_train['not2'] + y_pred_train['not0'] + y_pred_train['not4']\n",
    "    y_pred_train['4'] = y_pred_train['not1'] + y_pred_train['not2'] + y_pred_train['not3'] + y_pred_train['not0']\n",
    "\n",
    "    y_pred_holdout['0'] = y_pred_holdout['not1'] + y_pred_holdout['not2'] + y_pred_holdout['not3'] + y_pred_holdout[\n",
    "        'not4']\n",
    "    y_pred_holdout['1'] = y_pred_holdout['not0'] + y_pred_holdout['not2'] + y_pred_holdout['not3'] + y_pred_holdout[\n",
    "        'not4']\n",
    "    y_pred_holdout['2'] = y_pred_holdout['not1'] + y_pred_holdout['not0'] + y_pred_holdout['not3'] + y_pred_holdout[\n",
    "        'not4']\n",
    "    y_pred_holdout['3'] = y_pred_holdout['not1'] + y_pred_holdout['not2'] + y_pred_holdout['not0'] + y_pred_holdout[\n",
    "        'not4']\n",
    "    y_pred_holdout['4'] = y_pred_holdout['not1'] + y_pred_holdout['not2'] + y_pred_holdout['not3'] + y_pred_holdout[\n",
    "        'not0']\n",
    "\n",
    "    y_pred_test.drop(columns=['not0', 'not1', 'not2', 'not3', 'not4'], inplace=True)\n",
    "    y_pred_train.drop(columns=['not0', 'not1', 'not2', 'not3', 'not4'], inplace=True)\n",
    "    y_pred_holdout.drop(columns=['not0', 'not1', 'not2', 'not3', 'not4'], inplace=True)\n",
    "\n",
    "    y_pred_test.columns = [0, 1, 2, 3, 4]\n",
    "    y_pred_train.columns = [0, 1, 2, 3, 4]\n",
    "    y_pred_holdout.columns = [0, 1, 2, 3, 4]\n",
    "\n",
    "    y_pred_test = y_pred_test.idxmax(axis=1)\n",
    "    y_pred_train = y_pred_train.idxmax(axis=1)\n",
    "    y_pred_holdout = y_pred_holdout.idxmax(axis=1)\n",
    "    predictions = y_pred_holdout\n",
    "\n",
    "    test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "    kappa = cohen_kappa_score(y_test, y_pred_test, weights='quadratic')\n",
    "\n",
    "    print(\"Test set accuracy by \" + modelName + \" : {:.2f}\".format(test_acc))\n",
    "    print(\"Train set accuracy by \" + modelName + \" : {:.2f}\".format(train_acc))\n",
    "    print(\"Kappa by \" + modelName + \" : {:.2f}\".format(kappa))\n",
    "\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "\n",
    "    # fitting this on test set\n",
    "    print('Fitting the Model on Test Set')\n",
    "\n",
    "    petid = data_test['PetID']\n",
    "    final_pred = pd.Series(predictions, name='AdoptionSpeed')\n",
    "    submission = pd.concat([petid, final_pred], axis=1)\n",
    "    submission.to_csv('submission-'+abbv+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5.2.2 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 84)\n",
      "(14993, 89)\n",
      "(3948, 84)\n",
      "(3948, 89)\n",
      "Fitting 1st Model - Class 0 vs rest\n",
      "Fitting 2nd - Class 1 vs rest\n",
      "Fitting 3rd - Class 2 vs rest\n",
      "Fitting 4th - Class 3 vs rest\n",
      "Fitting 5th - class 4 vs rest\n",
      "Test set accuracy by XGBoost Classifier : 0.44\n",
      "Train set accuracy by XGBoost Classifier : 0.97\n",
      "Kappa by XGBoost Classifier : 0.38\n",
      "[[ 19  35  37   7  34]\n",
      " [ 26 316 266  96 192]\n",
      " [ 33 272 481 197 252]\n",
      " [ 27 137 272 275 249]\n",
      " [ 24  94 174  81 902]]\n",
      "Fitting the Model on Test Set\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xg_classifier = xgb.XGBClassifier(\n",
    "    max_depth=7, n_estimators=200)\n",
    "run_stacking_predictions(xg_classifier, 'XGBoost Classifier', 'xgb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 84)\n",
      "(14993, 89)\n",
      "(3948, 84)\n",
      "(3948, 89)\n",
      "Fitting 1st Model - Class 0 vs rest\n",
      "Fitting 2nd - Class 1 vs rest\n",
      "Fitting 3rd - Class 2 vs rest\n",
      "Fitting 4th - Class 3 vs rest\n",
      "Fitting 5th - class 4 vs rest\n",
      "Test set accuracy by Gradient Boosting Classifier : 0.46\n",
      "Train set accuracy by Gradient Boosting Classifier : 0.63\n",
      "Kappa by Gradient Boosting Classifier : 0.41\n",
      "[[ 16  36  26   7  26]\n",
      " [ 23 357 311  63 185]\n",
      " [ 19 211 472 182 300]\n",
      " [ 20 129 281 253 287]\n",
      " [ 15 102 167  56 954]]\n",
      "Fitting the Model on Test Set\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbm = GradientBoostingClassifier(random_state=15, n_estimators=250)\n",
    "run_stacking_predictions(gbm, \"Gradient Boosting Classifier\", 'gb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14993, 84)\n",
      "(14993, 89)\n",
      "(3948, 84)\n",
      "(3948, 89)\n",
      "Fitting 1st Model - Class 0 vs rest\n",
      "Fitting 2nd - Class 1 vs rest\n",
      "Fitting 3rd - Class 2 vs rest\n",
      "Fitting 4th - Class 3 vs rest\n",
      "Fitting 5th - class 4 vs rest\n",
      "Test set accuracy by Random Forest Classifier : 0.45\n",
      "Train set accuracy by Random Forest Classifier : 0.57\n",
      "Kappa by Random Forest Classifier : 0.36\n",
      "[[ 10  31  33   8  50]\n",
      " [  6 231 382  45 277]\n",
      " [  1 118 552 149 383]\n",
      " [  0  72 331 214 326]\n",
      " [  1  59 161  59 999]]\n",
      "Fitting the Model on Test Set\n"
     ]
    }
   ],
   "source": [
    "randomForest = RandomForestClassifier(random_state=1, n_estimators=300, max_depth=7)\n",
    "run_stacking_predictions(randomForest, \"Random Forest Classifier\", 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note: We are also submitting the following notebooks:\n",
    "1. Text Analysis Notebook\n",
    "2. EDA Notebook\n",
    "3. More deep dive into modelling  - where we analyze the feature importance and correlation heatmaps. Also, the logic to adjust class boundaries to improve the quadratic kappa score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
